{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cargan las librerias\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Información del dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trestbps  303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalach   303 non-null    int64  \n",
      " 8   exang     303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slope     303 non-null    int64  \n",
      " 11  ca        303 non-null    int64  \n",
      " 12  thal      303 non-null    int64  \n",
      " 13  target    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Cargar el dataset\n",
    "data = pd.read_csv('data/heart-disease.csv')\n",
    "\n",
    "# Exploración de datos\n",
    "print(\"Información del dataset:\")\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estadísticas descriptivas:\n",
      "              age         sex          cp    trestbps        chol         fbs  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
      "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
      "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
      "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
      "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
      "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
      "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
      "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
      "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
      "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
      "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
      "\n",
      "             thal      target  \n",
      "count  303.000000  303.000000  \n",
      "mean     2.313531    0.544554  \n",
      "std      0.612277    0.498835  \n",
      "min      0.000000    0.000000  \n",
      "25%      2.000000    0.000000  \n",
      "50%      2.000000    1.000000  \n",
      "75%      3.000000    1.000000  \n",
      "max      3.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores únicos en la variable 'target':\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValores únicos en la variable 'target':\")\n",
    "print(data['target'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se usaran distintos algoritmos de Machine Learning, para poder aumentar la precisión del modelo anteriormente mostrado."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la regresión logística: 0.8852459016393442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Dividir el dataset en características (X) y variable objetivo (y)\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Dividir el dataset en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión de la regresión logística:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del árbol de decisión: 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Crear el modelo de árbol de decisión\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del árbol de decisión:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosque aleatorio (Random Forest):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del bosque aleatorio: 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear el modelo de bosque aleatorio\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del bosque aleatorio:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquinas de vectores de soporte (Support Vector Machines, SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de las Máquinas de Vectores de Soporte: 0.7049180327868853\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Crear el modelo SVM\n",
    "model = SVC()\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión de las Máquinas de Vectores de Soporte:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí está la interpretación de los resultados de cada algoritmo:\n",
    "\n",
    "Regresión logística: La precisión de 0.8852 indica que el 88.52% de las predicciones realizadas por el modelo de regresión logística fueron correctas.\n",
    "\n",
    "Árbol de decisión: La precisión de 0.8033 significa que el 80.33% de las predicciones realizadas por el modelo de árbol de decisión fueron correctas.\n",
    "\n",
    "Bosque aleatorio: La precisión de 0.8689 indica que el 86.89% de las predicciones realizadas por el modelo de bosque aleatorio fueron correctas.\n",
    "\n",
    "Máquinas de Vectores de Soporte (SVM): La precisión de 0.7049 significa que el 70.49% de las predicciones realizadas por el modelo de Máquinas de Vectores de Soporte fueron correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión promedio de Regresión logística: 0.8282513661202187\n",
      "Precisión promedio de Árbol de decisión: 0.7687978142076503\n",
      "Precisión promedio de Bosque aleatorio: 0.8249726775956283\n",
      "Precisión promedio de Máquinas de Vectores de Soporte: 0.6434972677595628\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Dividir el dataset en características (X) y variable objetivo (y)\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Inicializar los modelos\n",
    "logistic_regression = LogisticRegression(max_iter=100000)  # Aumenta el número de iteraciones\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "svm = SVC()\n",
    "\n",
    "# Realizar la validación cruzada para cada modelo\n",
    "models = [logistic_regression, decision_tree, random_forest, svm]\n",
    "model_names = ['Regresión logística', 'Árbol de decisión', 'Bosque aleatorio', 'Máquinas de Vectores de Soporte']\n",
    "\n",
    "for model, name in zip(models, model_names):\n",
    "    scores = cross_val_score(model, X, y, cv=5)  # Realizar validación cruzada con 5 subdivisiones\n",
    "    print(f\"Precisión promedio de {name}: {np.mean(scores)}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se realizara el ajuste de hiperparámetros para obtener una mejor precisión"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de la regresión logística: 0.8524590163934426\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "model = LogisticRegression(solver='lbfgs', max_iter=1000000)\n",
    "\n",
    "# Definir los hiperparámetros que deseas ajustar\n",
    "param_grid = {'C': [0.1, 1.0, 10.0], 'penalty': ['l2']}  # Usar 'l2' en lugar de 'l1'\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y los mejores hiperparámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Entrenar el mejor modelo con los mejores hiperparámetros\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión de la regresión logística:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una cuadrícula de hiperparámetros param_grid que incluye diferentes valores para el parámetro de regularización C y el tipo de penalización penalty. Grid Search (GridSearchCV) se utiliza para buscar exhaustivamente los mejores hiperparámetros dentro de la cuadrícula definida. Después de la búsqueda, se obtiene el mejor modelo y los mejores hiperparámetros utilizando best_estimator_ y best_params_, respectivamente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árbol de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del árbol de decisión: 0.7377049180327869\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Crear el modelo de árbol de decisión\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# Definir los hiperparámetros que deseas ajustar\n",
    "param_grid = {'max_depth': [None, 5, 10], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando Randomized Search\n",
    "randomized_search = RandomizedSearchCV(model, param_grid, cv=5, n_iter=9)  # Ajustar el valor de n_iter\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y los mejores hiperparámetros\n",
    "best_model = randomized_search.best_estimator_\n",
    "best_params = randomized_search.best_params_\n",
    "\n",
    "# Entrenar el mejor modelo con los mejores hiperparámetros\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del árbol de decisión:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza Randomized Search (RandomizedSearchCV) para buscar los mejores hiperparámetros para el modelo de árbol de decisión. Se define una cuadrícula de hiperparámetros param_grid que incluye diferentes valores para la profundidad máxima del árbol (max_depth) y el número mínimo de muestras requeridas para dividir un nodo interno (min_samples_split).\n",
    "\n",
    "Y al ajustar n_iter=9, se asegura de que la búsqueda aleatoria se ejecute correctamente sin generar el mensaje de advertencia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del bosque aleatorio: 0.8360655737704918\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Crear el modelo de bosque aleatorio\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Definir los hiperparámetros que deseas ajustar\n",
    "param_grid = {'n_estimators': [100, 200, 500], 'max_depth': [None, 5, 10]}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando Randomized Search\n",
    "randomized_search = RandomizedSearchCV(model, param_grid, cv=5 , n_iter=9)\n",
    "randomized_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y los mejores hiperparámetros\n",
    "best_model = randomized_search.best_estimator_\n",
    "best_params = randomized_search.best_params_\n",
    "\n",
    "# Entrenar el mejor modelo con los mejores hiperparámetros\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión del bosque aleatorio:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza Randomized Search para buscar los mejores hiperparámetros para el modelo de bosque aleatorio. Se define una cuadrícula de hiperparámetros param_grid que incluye diferentes valores para el número de árboles en el bosque (n_estimators) y la profundidad máxima de los árboles (max_depth).\n",
    "\n",
    "Y al ajustar n_iter=9, se asegura de que la búsqueda aleatoria se ejecute correctamente sin generar el mensaje de advertencia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquinas de Vectores de Soporte (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión de las Máquinas de Vectores de Soporte: 0.8688524590163934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Crear el modelo SVM\n",
    "model = SVC()\n",
    "\n",
    "# Definir los hiperparámetros que deseas ajustar\n",
    "param_grid = {'C': [0.1, 1.0, 10.0], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "# Realizar la búsqueda de hiperparámetros utilizando Grid Search\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtener el mejor modelo y los mejores hiperparámetros\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Entrenar el mejor modelo con los mejores hiperparámetros\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión de las Máquinas de Vectores de Soporte:\", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utiliza Grid Search para buscar los mejores hiperparámetros para el modelo SVM. Se define una cuadrícula de hiperparámetros param_grid que incluye diferentes valores para el parámetro de regularización C y el tipo de kernel (linear y rbf)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
